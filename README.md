# ğŸ§ SVM Classification Project

This project demonstrates binary classification using **Support Vector Machines (SVM)** in Python. A custom modular class has been created to manage training, evaluation, and visualization. The notebook includes detailed data visualizations, model comparisons, and decision boundary plots.

> **Note**: Some visualizations might not render correctly when running the notebook locally. To view the complete notebook with all visualizations properly displayed, visit the Kaggle version here: [ğŸ”— View on Kaggle](https://www.kaggle.com/code/mohamedelgazar74/svm-classification)

---

## ğŸ“š Table of Contents

- [ğŸ“– Project Overview](#ğŸ“–-project-overview)
- [ğŸ› ï¸ Technologies Used](#ğŸ› ï¸-technologies-used)
- [ğŸ““ Notebook Structure (Important Cells)](#ğŸ““-notebook-structure-important-cells)
- [ğŸ§¹ Custom SVM Class](#ğŸ§¹-custom-svm-class)
- [ğŸ“Š Data Visualization](#ğŸ“Š-data-visualization)
- [â–¶ï¸ How to Run](#â–¶ï¸-how-to-run)
- [ğŸ† Results](#ğŸ†-results)
- [ğŸš€ Future Improvements](#ğŸš€-future-improvements)
- [ğŸ“œ License](#ğŸ“œ-license)

---

## ğŸ“– Project Overview

- Implement SVM for binary classification.
- Compare different kernel functions (**linear**, **polynomial**, **rbf**).
- Visualize datasets and decision boundaries.
- Use a **custom class** to organize the workflow (training, evaluation, plotting).

---

## ğŸ› ï¸ Technologies Used

- Python 3.x
- Jupyter Notebook
- NumPy
- Pandas
- Matplotlib
- Scikit-learn

---

## ğŸ““ Notebook Structure

| ğŸ§¹ Cell Stage | ğŸ“„ Description | â­ Importance |
|:-----------|:------------|:-----------|
| **Importing Libraries** | Import necessary libraries like `numpy`, `pandas`, `matplotlib`, `sklearn`. | Essential for enabling ML, visualization, and data handling. |
| **Data Loading** | Load datasets, typically synthetic (`make_moons`, `make_circles`, etc.) or real datasets. | Provides data for training and visualization. |
| **Data Visualization (Before Modeling)** | Plot the raw input data to understand its distribution and potential separability. | Helps see if linear/non-linear kernels will work better. |
| **Data Preprocessing** | Standardize features using `StandardScaler`. Split into training and test sets. | Ensures fair model training and testing. |
| **SVM Class Definition** | Define the custom `SVM` (Visual SVM) class. | Modularizes SVM logic: training, predicting, scoring, and plotting. |
| **Model Training (Linear Kernel)** | Train the SVM with a linear kernel using the `SVM` class. | First baseline model to compare. |
| **Visualization (Linear Kernel)** | Plot decision boundaries for linear SVM. | Check if data is linearly separable. |
| **Model Training (RBF Kernel)** | Train SVM with the RBF kernel. | Non-linear decision surface. |
| **Visualization (RBF Kernel)** | Plot decision boundaries for RBF SVM. | Shows improved fitting for curved boundaries. |
| **Model Training (Polynomial Kernel)** | Train SVM with polynomial kernel (typically degree 3). | Captures more complex non-linear patterns. |
| **Visualization (Polynomial Kernel)** | Plot decision boundaries for polynomial SVM. | Helps understand overfitting/underfitting. |
| **Comparison Summary** | Compare model accuracies and boundary plots. | Final evaluation of the best model. |

---

## ğŸ§¹ Custom SVM Class

The notebook defines a class named **`SVM`** to encapsulate the entire SVM workflow:

### âœ¨ Methods in the `SVM` Class:
- `__init__` â†’ Initialize SVM model with specified kernel and hyperparameters.
- `train(X_train, y_train)` â†’ Train the SVM model.
- `predict(X_test)` â†’ Make predictions.
- `evaluate(X_test, y_test)` â†’ Calculate accuracy and confusion matrix.
- `plot_decision_boundary(X, y)` â†’ Visualize decision regions and true labels.

âœ… **Benefits**:
- Code reusability
- Cleaner notebook
- Easier experimentation with different models

---

## ğŸ“Š Data Visualization

Visualization is a key strength of this notebook:

### 1. ğŸ“ **Initial Dataset Visualization**
- Scatter plots before any model training.
- Different classes are colored distinctly.
- Helps understand the complexity of the classification task.

### 2. ğŸ§ **Decision Boundary Visualization**
- After model training, the decision boundary is plotted.
- The boundary indicates regions classified as each class.
- Background color represents model prediction, points show true classes.
- Clear differences between Linear, RBF, and Polynomial kernels are visible:
  - **Linear Kernel**: â¡ï¸ Straight boundaries
  - **RBF Kernel**: ğŸ”µ Curved boundaries adapting to data
  - **Polynomial Kernel**: ğŸˆ Complex and flexible curves

---

## â–¶ï¸ How to Run

1. Clone the repository or download the notebook. ğŸ‘…
2. Install required libraries:
   ```bash
   pip install -r requirements.txt
   ```
3. Open and run:
   ```bash
   jupyter notebook SVM-Classification.ipynb
   ```
4. Execute all cells sequentially to experience the full workflow. âš¡ï¸

> **Reminder**: If visualizations don't appear correctly locally, you can see the full version on Kaggle: [ğŸ”— Kaggle Notebook](https://www.kaggle.com/code/mohamedelgazar74/svm-classification)

---

## ğŸ† Results

- **Linear SVM** performed well for linearly separable data but struggled on curves.
- **RBF Kernel** provided best results for non-linear datasets.
- **Polynomial Kernel** worked well but may overfit depending on the degree.
- Clear visualization helped easily differentiate model performances.

---

## ğŸš€ Future Improvements

- Apply **GridSearchCV** for automated hyperparameter tuning. ğŸ”
- Test on real-world datasets (e.g., breast cancer, digits). ğŸ§¬
- Extend the `SVM` class for multi-class classification (One-vs-One, One-vs-Rest). â•

---

## ğŸ“œ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

---

